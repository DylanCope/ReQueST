# python3
# Copyright 2019 DeepMind Technologies Limited
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
"""Generative models for images that can encode, decode, and compute likelihoods"""

from __future__ import division

import uuid
import os

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

from rqst.models import TFModel
from rqst import utils


class EncoderModel(TFModel):

  def encode_batch_frames(self, obses):
    """
    Args:
     obses: a np.array with dimensions (batch_size, W, H, C)
    Returns:
     a np.array with dimensions (batch_size, n_z_dim)
    """
    return self.encode(self.squash_obs(obses))

  def decode_batch_latents(self, latents):
    """
    Args:
     latents: a np.array with dimensions (batch_size, n_z_dim)
    Returns:
     a np.array with dimensions (batch_size, W, H, C)
    """
    return self.decode(latents)

  def squash_obs(self, obs):
    """
    Args:
     obs: a np.array with dimensions (batch_size, W, H, C) or (W, H, C)
    Returns:
     a np.array with dimensions (batch_size, W, H, C) or (W, H, C)
     copy of obs, with pixel values squashed to [0, 1]
    """
    obs_max = obs.max()
    obs_norm = 255. if obs_max > 1. else 1.
    return obs / obs_norm

  def encode_frame(self, obs):
    """
    Args:
     obs: a np.array with dimensions (W, H, C)
    Returns:
     a np.array with dimensions (n_z_dim)
    """
    return self.encode(self.squash_obs(obs[np.newaxis, :, :, :]))[0, :]

  def decode_latent(self, latent):
    """
    Args:
     latent: a np.array with dimensions (n_z_dim)
    Returns:
     a np.array with dimensions (W, H, C)
    """
    return self.decode(latent[np.newaxis, :])[0, :, :, :]


class IdenModel(EncoderModel):
  """Pass-through encoder-decoder"""

  def __init__(self, *args, **kwargs):

    super().__init__(*args, **kwargs)

    if self.env.name != 'clfbandit':
      raise NotImplementedError

  def encode(self, input_x):
    return input_x.reshape(
        (input_x.shape[0], input_x.shape[1] * input_x.shape[2]))

  def decode(self, code_z):
    d = int(np.sqrt(code_z.shape[1]))
    return code_z.reshape((code_z.shape[0], d, d, 1))

  def log_prob_latent(self, latent):
    return 0. # uniform likelihood


class VAEModel(EncoderModel):
  """Adapted from https://github.com/hardmaru/WorldModelsExperiments/blob/master/carracing/"""

  def __init__(self, *args, kl_tolerance=0.5, **kwargs):

    super().__init__(*args, **kwargs)

    if self.env.name not in ['clfbandit', 'carracing']:
      raise ValueError

    self.data_keys = ['obses']

    if self.env.name == 'carracing':
      # takes frames generated by utils.process_frame
      input_shape = [None, 64, 64, 3]
    elif self.env.name == 'clfbandit':
      input_shape = [None, 28, 28, 1]
    self.input_x_ph = tf.placeholder(tf.float32, shape=input_shape)

    with tf.variable_scope(self.scope, reuse=tf.AUTO_REUSE):
      vae_out_vars = self.build_vae_net(self.input_x_ph)
    self.__dict__.update(vae_out_vars)

    if 'loss' not in vae_out_vars:
      # reconstruction
      r_loss = tf.reduce_sum(
          tf.square(self.input_x_ph - self.output_y),
          reduction_indices=[1, 2, 3])
      r_loss = tf.reduce_mean(r_loss)

      # regularization
      kl_loss = -0.5 * tf.reduce_sum(
          (1 + self.logvar - tf.square(self.mu) - tf.exp(self.logvar)),
          reduction_indices=1)
      kl_loss = tf.maximum(kl_loss, kl_tolerance * self.env.n_z_dim)
      kl_loss = tf.reduce_mean(kl_loss)

      self.loss = r_loss + kl_loss

  def build_encoder(self, input_x):
    if self.env.name == 'carracing':
      h = tf.layers.conv2d(
          input_x, 32, 4, strides=2, activation=tf.nn.relu, name='enc_conv1')
      h = tf.layers.conv2d(
          h, 64, 4, strides=2, activation=tf.nn.relu, name='enc_conv2')
      h = tf.layers.conv2d(
          h, 128, 4, strides=2, activation=tf.nn.relu, name='enc_conv3')
      h = tf.layers.conv2d(
          h, 256, 4, strides=2, activation=tf.nn.relu, name='enc_conv4')
      h = tf.reshape(h, [tf.shape(h)[0], 2 * 2 * 256])
    elif self.env.name == 'clfbandit':
      batch_size = tf.shape(input_x)[0]
      flat_input = tf.reshape(input_x, [batch_size, 28 * 28])
      h = tf.layers.dense(flat_input, 256, name='enc_fc1')
      h = tf.layers.dense(h, 128, name='enc_fc2')
    return h

  def build_decoder(self, code_z):
    if self.env.name == 'carracing':
      h = tf.layers.dense(code_z, 2 * 2 * 256, name='dec_fc')
      h = tf.reshape(h, [tf.shape(code_z)[0], 1, 1, 2 * 2 * 256])
      h = tf.layers.conv2d_transpose(
          h, 128, 5, strides=2, activation=tf.nn.relu, name='dec_deconv1')
      h = tf.layers.conv2d_transpose(
          h, 64, 5, strides=2, activation=tf.nn.relu, name='dec_deconv2')
      h = tf.layers.conv2d_transpose(
          h, 32, 6, strides=2, activation=tf.nn.relu, name='dec_deconv3')
      output_y = tf.layers.conv2d_transpose(
          h, 3, 6, strides=2, activation=tf.nn.sigmoid, name='dec_deconv4')
    elif self.env.name == 'clfbandit':
      h = tf.layers.dense(code_z, 128, name='dec_fc1')
      h = tf.layers.dense(h, 256, name='dec_fc2')
      h = tf.layers.dense(h, 28 * 28, name='dec_fc3')
      h = tf.sigmoid(h)
      batch_size = tf.shape(h)[0]
      output_y = tf.reshape(h, [batch_size, 28, 28, 1])
    return output_y

  def build_vae_net(self, input_x):
    h = self.build_encoder(input_x)

    mu = tf.layers.dense(h, self.env.n_z_dim, name='enc_fc_mu')
    logvar = tf.layers.dense(h, self.env.n_z_dim, name='enc_fc_log_var')
    sigma = tf.exp(logvar / 2.0)
    epsilon = tf.random_normal(tf.shape(mu))
    code_z = mu + sigma * epsilon

    output_y = self.build_decoder(code_z)
    output_y = tf.clip_by_value(output_y, 1e-8, 1 - 1e-8)

    return {
        'code_z': code_z,
        'output_y': output_y,
        'mu': mu,
        'logvar': logvar,
        'sigma': sigma,
        'epsilon': epsilon
    }

  def format_batch(self, batch):
    """
    Args:
     batch: a dict containing the output of a call to rqst.utils.vectorize_rollouts
      batch['obses'] maps to a np.array with dimensions (batch_size, W, H, C)
    Returns:
      a dict containing the input for a call to rqst.models.TFModel.compute_batch_loss
    """
    feed_dict = {self.input_x_ph: self.squash_obs(batch['obses'].astype(float))}
    return feed_dict

  def encode(self, input_x):
    """
    Args:
     input_x: a np.array with dimensions (batch_size, W, H, C)
    Returns:
     a np.array with dimensions (batch_size, n_z_dim)
    """
    feed_dict = {self.input_x_ph: input_x}
    return self.sess.run(self.mu, feed_dict=feed_dict)

  def encode_mu_logvar(self, input_x):
    """Useful for rqst.dynamics_models.MDNRNNDynamicsModel.preproc_rollouts
    Args:
     input_x: np (batch_size, W, H, C)
    Returns:
     a tuple containing (a np.array with dimensions (batch_size, n_z_dim),
      a np.array with dimensions (batch_size, n_z_dim))
    """
    feed_dict = {self.input_x_ph: self.squash_obs(input_x)}
    mu, logvar = self.sess.run([self.mu, self.logvar], feed_dict=feed_dict)
    return mu, logvar

  def decode(self, code_z):
    """
    Args:
     code_z: a np.array with dimensions (batch_size, n_z_dim)
    Returns:
     a np.array with dimensions (batch_size, W, H, C)
    """
    feed_dict = {self.code_z: code_z}
    return self.sess.run(self.output_y, feed_dict=feed_dict)

  def log_prob_latent(self, latent):
    """
    Args:
     latent: a tf.Tensor with dimensions (n_z_dim)
    Returns:
     a tf.Tensor with dimensions (1)
    """
    return -tf.reduce_mean(latent**2)


class MNISTVAEModel(VAEModel):
  """Adapted from https://github.com/hwalsuklee/tensorflow-mnist-VAE"""

  def __init__(self, *args, **kwargs):

    self.img_dim = 28
    self.layer_size = 256

    super().__init__(*args, **kwargs)

  def build_encoder(self, x, n_hidden, n_output):
    with tf.variable_scope('gaussian_MLP_encoder'):
      # initializers
      w_init = tf.contrib.layers.variance_scaling_initializer()
      b_init = tf.constant_initializer(0.)

      # 1st hidden layer
      w0 = tf.get_variable(
          'w0', [x.get_shape()[1], n_hidden], initializer=w_init)
      b0 = tf.get_variable('b0', [n_hidden], initializer=b_init)
      h0 = tf.matmul(x, w0) + b0
      h0 = tf.nn.elu(h0)

      # 2nd hidden layer
      w1 = tf.get_variable(
          'w1', [h0.get_shape()[1], n_hidden], initializer=w_init)
      b1 = tf.get_variable('b1', [n_hidden], initializer=b_init)
      h1 = tf.matmul(h0, w1) + b1
      h1 = tf.nn.tanh(h1)

      # output layer
      # borrowed from https://github.com/altosaar/vae/blob/master/vae.py
      wo = tf.get_variable(
          'wo', [h1.get_shape()[1], n_output * 2], initializer=w_init)
      bo = tf.get_variable('bo', [n_output * 2], initializer=b_init)
      gaussian_params = tf.matmul(h1, wo) + bo

      # The mean parameter is unconstrained
      mean = gaussian_params[:, :n_output]
      # The standard deviation must be positive. Parametrize with a softplus and
      # add a small epsilon for numerical stability
      stddev = 1e-6 + tf.nn.softplus(gaussian_params[:, n_output:])

    return mean, stddev

  def build_decoder(self, z, n_hidden, n_output, reuse=False):
    with tf.variable_scope('bernoulli_MLP_decoder', reuse=reuse):
      # initializers
      w_init = tf.contrib.layers.variance_scaling_initializer()
      b_init = tf.constant_initializer(0.)

      # 1st hidden layer
      w0 = tf.get_variable(
          'w0', [z.get_shape()[1], n_hidden], initializer=w_init)
      b0 = tf.get_variable('b0', [n_hidden], initializer=b_init)
      h0 = tf.matmul(z, w0) + b0
      h0 = tf.nn.tanh(h0)

      # 2nd hidden layer
      w1 = tf.get_variable(
          'w1', [h0.get_shape()[1], n_hidden], initializer=w_init)
      b1 = tf.get_variable('b1', [n_hidden], initializer=b_init)
      h1 = tf.matmul(h0, w1) + b1
      h1 = tf.nn.elu(h1)

      # output layer-mean
      wo = tf.get_variable(
          'wo', [h1.get_shape()[1], n_output], initializer=w_init)
      bo = tf.get_variable('bo', [n_output], initializer=b_init)
      y = tf.sigmoid(tf.matmul(h1, wo) + bo)

    return y

  def build_vae_net(self, input_x):
    batch_size = tf.shape(input_x)[0]
    input_x = tf.reshape(input_x, [batch_size, self.img_dim**2])

    # encoding
    mu, sigma = self.build_encoder(input_x, self.layer_size, self.env.n_z_dim)

    # sampling by re-parameterization technique
    z = mu + sigma * tf.random_normal(tf.shape(mu), 0, 1, dtype=tf.float32)

    # decoding
    y = self.build_decoder(z, self.layer_size, self.img_dim**2)
    y = tf.clip_by_value(y, 1e-8, 1 - 1e-8)

    # loss
    marginal_likelihood = tf.reduce_sum(
        input_x * tf.log(y) + (1 - input_x) * tf.log(1 - y), 1)
    KL_divergence = 0.5 * tf.reduce_sum(
        tf.square(mu) + tf.square(sigma) - tf.log(1e-8 + tf.square(sigma)) - 1,
        1)

    marginal_likelihood = tf.reduce_mean(marginal_likelihood)
    KL_divergence = tf.reduce_mean(KL_divergence)

    ELBO = marginal_likelihood - KL_divergence

    loss = -ELBO

    batch_size = tf.shape(y)[0]
    y = tf.reshape(y, [batch_size, self.img_dim, self.img_dim, 1])

    return {'mu': mu, 'output_y': y, 'loss': loss, 'code_z': z}

  def train(self,
            data,
            iterations=100000,
            ftol=1e-4,
            batch_size=32,
            learning_rate=1e-3,
            val_update_freq=100,
            verbose=False):

    if self.loss is None:
      return

    opt_scope = utils.opt_scope_of_obj(self)
    with tf.variable_scope(opt_scope, reuse=tf.AUTO_REUSE):
      self.update_op = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)

    utils.init_tf_vars(self.sess, [self.scope, opt_scope])

    val_losses = []
    val_batch = utils.sample_batch(
        size=len(data['val_idxes']),
        data=data,
        data_keys=self.data_keys,
        idxes_key='val_idxes')

    if verbose:
      print('iters total_iters train_loss val_loss')

    for t in range(iterations):
      batch = utils.sample_batch(
          size=batch_size,
          data=data,
          data_keys=self.data_keys,
          idxes_key='train_idxes',
          class_idxes_key='train_idxes_of_act')

      train_loss = self.compute_batch_loss(self.format_batch(batch), update=True)

      if t % val_update_freq == 0:
        val_loss = self.compute_batch_loss(self.format_batch(val_batch), update=False)

        if verbose:
          print('%d %d %f %f' % (t, iterations, train_loss, val_loss))

        val_losses.append(val_loss)

        if utils.converged(val_losses, ftol):
          break

    if verbose:
      plt.plot(val_losses)
      plt.show()


def load_wm_pretrained_vae(sess, env):
  scope = 'conv_vae'
  jsonfile = os.path.join(utils.wm_dir, 'vae', 'vae.json')
  encoder = VAEModel(
      sess,
      env,
      learning_rate=0.0001,
      kl_tolerance=0.5,
      scope=scope,
      scope_file=os.path.join(utils.carracing_data_dir, 'enc_scope.pkl'),
      tf_file=os.path.join(utils.carracing_data_dir, 'enc.tf'))
  utils.load_wm_pretrained_model(jsonfile, scope, sess)
  return encoder
